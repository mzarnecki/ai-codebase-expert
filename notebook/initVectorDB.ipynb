{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup Docker container for DB and install lib",
   "id": "441ed5a009be43e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!pip install -qU langchain_postgres\n",
    "# run postgres pg_vector docker with command: docker compose up\n"
   ],
   "id": "9b0d2c0d145d3488",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup Postgres pg_vector Vector Store and function for importing documents",
   "id": "b084b39502120b4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from app.db.VectorStore import VectorStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from app.db.EnumDocsCollection import EnumDocsCollection\n",
    "\n",
    "def purify_HTML(html: str)->str:\n",
    "    soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()    # rip it out\n",
    "\n",
    "    text = soup.get_text()\n",
    "\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "    return text\n",
    "\n",
    "\n",
    "def import_source_documents(folder: str):\n",
    "    # Split documents and store in vector db\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=10000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "\n",
    "    vectordb = VectorStore.get_vector_store(folder)\n",
    "    dir = os.path.join(\"../data/\", folder)\n",
    "    for root, d_names, f_names in os.walk(dir):\n",
    "        progress_bar = tqdm(f_names)\n",
    "        for file in progress_bar:\n",
    "            progress_bar.set_description(file)\n",
    "            if not os.path.isdir(file):\n",
    "                with open(os.path.join(root, file)) as f:\n",
    "                    splits = []\n",
    "                    if file.endswith(\".png\") or file.endswith(\".jpg\") or file.endswith(\".jpeg\"):\n",
    "                        continue\n",
    "                    try:\n",
    "                        text = f.read()\n",
    "                        if file.endswith(\".html\"):\n",
    "                            text = purify_HTML(text)\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "\n",
    "                    for idx, chunk in enumerate(text_splitter.split_text(text)):\n",
    "                        splits.append(Document(\n",
    "                            page_content=chunk,\n",
    "                            metadata={\"source\": file, \"chunk_idx\": idx}\n",
    "                        ))\n",
    "                    try:\n",
    "                        vectordb.add_documents(splits)\n",
    "                    except Exception as e:\n",
    "                        print(e)"
   ],
   "id": "211bc91e0f7df3f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Base Information",
   "id": "e12016c6443ee360"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vectordb = VectorStore.get_vector_store(EnumDocsCollection.BASE_INFO.value)\n",
    "vectordb.drop_tables()"
   ],
   "id": "5eb7e0e716bb310f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import_source_documents(EnumDocsCollection.BASE_INFO.value)",
   "id": "ff237c014d52b0ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Companyhouse Project Code",
   "id": "80f628e33160299f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import_source_documents(EnumDocsCollection.COMPANYHOUSE_PROJ_CODE.value)",
   "id": "1947c94afc8db057",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Framework Documentation",
   "id": "f2e59e82ca8812b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import_source_documents(EnumDocsCollection.FRAMEWORK_DOCS.value)",
   "id": "86c8f80469dc6770",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Companyhouse Documentation",
   "id": "20050166a43a574f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import_source_documents(EnumDocsCollection.COMPANYHOUSE_PROJ_DOCS.value)",
   "id": "57c1d5725dfae77a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
