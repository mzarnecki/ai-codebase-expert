{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup Docker container for DB and install lib",
   "id": "441ed5a009be43e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T07:16:35.583007Z",
     "start_time": "2025-01-03T07:16:33.742627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install -qU langchain_postgres\n",
    "# run postgres pg_vector docker with command: docker compose up\n"
   ],
   "id": "9b0d2c0d145d3488",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup Postgres pg_vector Vector Store and function for importing documents",
   "id": "b084b39502120b4d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T07:16:35.601601Z",
     "start_time": "2025-01-03T07:16:35.595380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import os\n",
    "from app.db.VectorStore import VectorStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from app.db.EnumDocsCollection import EnumDocsCollection\n",
    "\n",
    "def purify_HTML(html: str)->str:\n",
    "    soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()    # rip it out\n",
    "\n",
    "    text = soup.get_text()\n",
    "\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "    return text\n",
    "\n",
    "\n",
    "def import_source_documents(folder:str, verbose:bool=True, only_php:bool = False):\n",
    "    # Split documents and store in vector db\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=10000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "\n",
    "    vectordb = VectorStore.get_vector_store(folder)\n",
    "    dir = os.path.join(\"../data/\", folder)\n",
    "    for root, d_names, f_names in os.walk(dir):\n",
    "        if verbose:\n",
    "            progress_bar = tqdm(f_names)\n",
    "        else:\n",
    "            progress_bar = f_names\n",
    "        for file in progress_bar:\n",
    "            if verbose:\n",
    "                progress_bar.set_description(file)\n",
    "            if not os.path.isdir(file):\n",
    "                with open(os.path.join(root, file), 'rb') as f:\n",
    "                    splits = []\n",
    "                    if only_php and not file.endswith(\".php\"):\n",
    "                        continue\n",
    "                    if file.endswith(\".png\") or file.endswith(\".jpg\") or file.endswith(\".jpeg\") or file.endswith(\".mp4\"):\n",
    "                        continue\n",
    "                    try:\n",
    "                        text = f.read().decode(errors='replace')\n",
    "                        if file.endswith(\".html\"):\n",
    "                            text = purify_HTML(text)\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "\n",
    "                    text = re.sub(r'\\{[\\w_-]+\\}', '', text)\n",
    "\n",
    "                    for idx, chunk in enumerate(text_splitter.split_text(text)):\n",
    "                        splits.append(Document(\n",
    "                            page_content=chunk,\n",
    "                            metadata={\"source\": file, \"path\": os.path.join(root, file), \"chunk_idx\": idx}\n",
    "                        ))\n",
    "                    try:\n",
    "                        vectordb.add_documents(splits)\n",
    "                    except Exception as e:\n",
    "                        print(e)"
   ],
   "id": "211bc91e0f7df3f8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Base Information",
   "id": "e12016c6443ee360"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T07:16:36.145939Z",
     "start_time": "2025-01-03T07:16:35.645490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vectordb = VectorStore.get_vector_store(EnumDocsCollection.BASE_INFO.value)\n",
    "vectordb.drop_tables()"
   ],
   "id": "5eb7e0e716bb310f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4be57c4e083344ca851d310e2563061a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T07:16:47.377618Z",
     "start_time": "2025-01-03T07:16:46.266215Z"
    }
   },
   "cell_type": "code",
   "source": "import_source_documents(EnumDocsCollection.BASE_INFO.value)",
   "id": "ff237c014d52b0ce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89e3ed058c204f228bd990b382dd5e3a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "companyhouseWiki.txt: 100%|██████████| 2/2 [00:00<00:00,  3.46it/s]         \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Companyhouse Project Code",
   "id": "80f628e33160299f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T07:50:45.089223Z",
     "start_time": "2025-01-03T07:16:47.388701Z"
    }
   },
   "cell_type": "code",
   "source": "import_source_documents(EnumDocsCollection.COMPANYHOUSE_PROJ_CODE.value, verbose=False, only_php=True)",
   "id": "1947c94afc8db057",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b218ed2cb814af287d832150f8cd177"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(psycopg.errors.NotNullViolation) null value in column \"id\" of relation \"langchain_pg_embedding\" violates not-null constraint\n",
      "DETAIL:  Failing row contains (null, null, null, null, null).\n",
      "[SQL: INSERT INTO langchain_pg_embedding DEFAULT VALUES ON CONFLICT (id) DO UPDATE SET embedding = excluded.embedding, document = excluded.document, cmetadata = excluded.cmetadata]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "(psycopg.errors.NotNullViolation) null value in column \"id\" of relation \"langchain_pg_embedding\" violates not-null constraint\n",
      "DETAIL:  Failing row contains (null, null, null, null, null).\n",
      "[SQL: INSERT INTO langchain_pg_embedding DEFAULT VALUES ON CONFLICT (id) DO UPDATE SET embedding = excluded.embedding, document = excluded.document, cmetadata = excluded.cmetadata]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "(psycopg.errors.NotNullViolation) null value in column \"id\" of relation \"langchain_pg_embedding\" violates not-null constraint\n",
      "DETAIL:  Failing row contains (null, null, null, null, null).\n",
      "[SQL: INSERT INTO langchain_pg_embedding DEFAULT VALUES ON CONFLICT (id) DO UPDATE SET embedding = excluded.embedding, document = excluded.document, cmetadata = excluded.cmetadata]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "(psycopg.errors.NotNullViolation) null value in column \"id\" of relation \"langchain_pg_embedding\" violates not-null constraint\n",
      "DETAIL:  Failing row contains (null, null, null, null, null).\n",
      "[SQL: INSERT INTO langchain_pg_embedding DEFAULT VALUES ON CONFLICT (id) DO UPDATE SET embedding = excluded.embedding, document = excluded.document, cmetadata = excluded.cmetadata]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "(psycopg.errors.NotNullViolation) null value in column \"id\" of relation \"langchain_pg_embedding\" violates not-null constraint\n",
      "DETAIL:  Failing row contains (null, null, null, null, null).\n",
      "[SQL: INSERT INTO langchain_pg_embedding DEFAULT VALUES ON CONFLICT (id) DO UPDATE SET embedding = excluded.embedding, document = excluded.document, cmetadata = excluded.cmetadata]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Framework Documentation",
   "id": "f2e59e82ca8812b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T08:05:02.027629Z",
     "start_time": "2025-01-03T07:50:45.182871Z"
    }
   },
   "cell_type": "code",
   "source": "import_source_documents(EnumDocsCollection.FRAMEWORK_DOCS.value)",
   "id": "86c8f80469dc6770",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f4c93125ca8f4906a69a34b016c4e021"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "guide-tutorial-core-validators.html: 100%|██████████| 858/858 [14:16<00:00,  1.00it/s]                         \n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Companyhouse Documentation",
   "id": "20050166a43a574f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T08:05:25.743985Z",
     "start_time": "2025-01-03T08:05:02.052580Z"
    }
   },
   "cell_type": "code",
   "source": "import_source_documents(EnumDocsCollection.COMPANYHOUSE_PROJ_DOCS.value)",
   "id": "57c1d5725dfae77a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db537a2cf9de4c1bae8fc388a044d132"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sitemaps_2239660052.html: 100%|██████████| 122/122 [00:22<00:00,  5.41it/s]                                                               \n",
      "0it [00:00, ?it/s]\n",
      "wait.gif:   0%|          | 0/3 [00:00<?, ?it/s]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(psycopg.DataError) PostgreSQL text fields cannot contain NUL (0x00) bytes\n",
      "[SQL: INSERT INTO langchain_pg_embedding (id, collection_id, embedding, document, cmetadata) VALUES (%(id_m0)s::VARCHAR, %(collection_id_m0)s::UUID, %(embedding_m0)s, %(document_m0)s::VARCHAR, %(cmetadata_m0)s::JSONB) ON CONFLICT (id) DO UPDATE SET embedding = excluded.embedding, document = excluded.document, cmetadata = excluded.cmetadata]\n",
      "[parameters: {'id_m0': '6caed318-055f-4178-85fd-bbda4f7e1f50', 'collection_id_m0': UUID('ab3f5a17-d0b5-45ec-a6dd-567660ada528'), 'embedding_m0': '[-0.042048949748277664,-0.0626618042588234,-0.006961728911846876,0.011563229374587536,0.07049935311079025,0.05394190922379494,0.03512005880475044,-0. ... (7779 characters truncated) ... -0.015553394332528114,-0.0005527643370442092,-0.010515833273530006,-0.0378003790974617,0.02900931052863598,0.019590334966778755,-0.04052946716547012]', 'document_m0': 'GIF89a\\x08\\x00\\x08\\x00�\\x00\\x00\\x003f����\\x01\\x02\\x00\\x00\\x00!�\\x04\\x04\\x14\\x00�\\x00,\\x00\\x00\\x00\\x00\\x08\\x00\\x08\\x00\\x00\\x02\\r�\\x7f�k��T��ՇN\\x01\\x00;', 'cmetadata_m0': Jsonb({'source': 'bullet_blue.gif', 'path ... (126 chars))}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/9h9h)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grey_arrow_down.png: 100%|██████████| 3/3 [00:00<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(psycopg.DataError) PostgreSQL text fields cannot contain NUL (0x00) bytes\n",
      "[SQL: INSERT INTO langchain_pg_embedding (id, collection_id, embedding, document, cmetadata) VALUES (%(id_m0)s::VARCHAR, %(collection_id_m0)s::UUID, %(embedding_m0)s, %(document_m0)s::VARCHAR, %(cmetadata_m0)s::JSONB) ON CONFLICT (id) DO UPDATE SET embedding = excluded.embedding, document = excluded.document, cmetadata = excluded.cmetadata]\n",
      "[parameters: {'id_m0': '4119ae4a-6f9f-459f-9c4c-d0d7804cd244', 'collection_id_m0': UUID('ab3f5a17-d0b5-45ec-a6dd-567660ada528'), 'embedding_m0': '[-0.027231479063630104,-0.009448573924601078,-0.037720050662755966,-0.01267452072352171,0.06857317686080933,0.04242289438843727,-0.01593729481101036, ... (7826 characters truncated) ... -0.00025657261721789837,-0.04906648024916649,-0.05005236715078354,-0.0427401103079319,-0.060333117842674255,0.02214096300303936,0.007210333365947008]', 'document_m0': 'GIF89a\\x10\\x00\\x10\\x00�\\x00\\x00��������ݻ�����������wwwfffUUUDDD333\"\"\"\\x11\\x11\\x11\\x00\\x11\\x00\\x00\\x00\\x00���\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ ... (2805 characters truncated) ... 0��B��B \\n�\\x02m\\x14�\\n�A�72,\\x14\\n��(P\\x1d\\x18X鲪��\\x06\\t��\\x148@R%�a\\x0c\\tK\\x11�*��\\x13�D�����2E\\x01\\x0b\\x08\\x10{\\x10\\x04\\x07\\x7f$��f\\x10t5�C%!\\x00;', 'cmetadata_m0': Jsonb({'source': 'wait.gif', 'path': '../ ... (112 chars))}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/9h9h)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smile.png: 100%|██████████| 3/3 [00:00<00:00, 648.57it/s]\n",
      "1fa99.png: 100%|██████████| 18/18 [00:00<00:00, 1574.93it/s]    \n",
      "home_page_16.png: 100%|██████████| 1/1 [00:00<00:00, 1664.41it/s]\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
